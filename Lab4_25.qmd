---
title: "DSAN5600 Lab4: ARIMA and SARIMA Models"
author: "Dr. Purna Gamage"
format: 
  html:
    embed-resources: true
editor: visual
toc: true
---

```{r, echo=FALSE,message=FALSE,warning=FALSE}
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa) 
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(tidyverse)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
library(ggplot2)
library(dplyr)
```


# ARIMA Model

## Class Example

### Step 1: Plotting the data

As with any data analysis, the first step is to create a time plot of the data to visually inspect for any irregularities or patterns.

We will use [Job Postings on Indeed in the United States](https://fred.stlouisfed.org/series/IHLIDXUS) as our example dataset.

```{r, warning=FALSE, message=FALSE}


###### Load Indeed Data and Rename Columns ######
indeed_data <- read.csv("indeed.csv")
colnames(indeed_data) <- c("Date", "job_postings")

###### Plot Original Data using Plotly ######
plot_ly(indeed_data, x = ~as.Date(Date)) %>%
  add_lines(y = ~job_postings, name = 'Original Job Postings', line = list(color = 'blue')) %>%
  layout(title = "Original Job Postings",
         xaxis = list(title = "Date"),
         yaxis = list(title = "Job Postings"))

```

The plot of job postings on Indeed in the United States from 2020 to 2025 reflects significant economic shifts over this period. A sharp decline in early 2020 corresponds to the onset of the COVID-19 pandemic, followed by a rapid recovery in 2021 as businesses adapted and reopened. Job postings peaked in early 2022, likely driven by post-pandemic economic optimism and increased hiring demand. However, from mid-2022 onward, there was a steady decline, suggesting a cooling labor market potentially influenced by inflation, rising interest rates, and broader economic tightening. By 2024, the decline stabilized, indicating that the job market may have reached a new equilibrium with more consistent, albeit cautious, hiring patterns.

**Converting Stock to a Time Series Object**

To proceed with modeling, it’s essential to convert the stock prices into a **time series object**. This format allows us to apply time series analysis techniques effectively, ensuring that the temporal structure of the data is preserved.

*Note:* We are currently working with a **univariate time series**, focusing solely on number of jobs posted in [indeed.com](https://www.indeed.com/).

```{r, warning=FALSE, message=FALSE}


###### Convert to Time Series Object ######
ts_indeed <- ts(indeed_data$job_postings, 
                start = decimal_date(as.Date(min(indeed_data$Date))), 
                frequency = 365.25)  # Daily data
```

**Checking for Stationarity and Serial Correlation**

Before fitting an ARIMA model, it’s crucial to determine if the series is stationary—meaning its statistical properties, like mean and variance, remain consistent over time.

### Step 2: Make the time series stationary


Let's go back to our example.

```{r, warning=FALSE, message=FALSE}


# Plot the Autocorrelation Function (ACF) for Original Data
ggAcf(ts_indeed, 50) +
  ggtitle("Autocorrelation Function of Original Job Postings") +
  theme_minimal()

```

To assess serial correlation, we use the Autocorrelation Function (ACF) plot. The ACF plot shows clear signs of high serial correlation, indicating that past values significantly influence future values. This indicates **differencing** is needed to achieve stationarity.

```{r, warning=FALSE, message=FALSE}

# Lag plot to visualize patterns in Original Data
gglagplot(ts_indeed, do.lines = FALSE) +
  ggtitle("Lag Plot of Original Job Postings") +
  theme_minimal()
```

Lag plots indicate the same high correlation that is visible in the ACF plot.

### Augmented Dickey Fuller (ADF) Test

The null hypothesis of the ADF test is that the **time series is non-stationary**.

So, if the p-value of the test is less than the significance level (0.05) then you reject the null hypothesis and infer that the time series is indeed **stationary** at 5% significance level.

So, in our case, if **P Value \> 0.05** indicate non-stationarity. Therefore, we go ahead with differencing the data to make the process stationary.

```{r, warning=FALSE, message=FALSE}

tseries::adf.test(ts_indeed)
```

P-value is greater than the significance level of 0.05 indicating that the series is not stationary.

### Differencing

The purpose of differencing is to transform the time series into a stationary one, where statistical properties remain constant over time. 

```{r, warning=FALSE, message=FALSE}

###### Differencing the Data ######
diff_indeed <- diff(ts_indeed)

# Plot Differenced Original Data
p1 <- ggplot() +
  geom_line(aes(x = time(diff_indeed), y = diff_indeed), color = "blue") +
  labs(title = "Differenced Original Job Postings",
       x = "Time",
       y = "Differenced Job Postings") +
  theme_minimal()

# Display the Differenced Plot
p1
```

#### Order of Differencing

```{r, warning=FALSE, message=FALSE}



library(patchwork)

###### First and Second Order Differencing ######
# First-order differencing
diff_1 <- diff(ts_indeed)

# Second-order differencing
diff_2 <- diff(ts_indeed, differences = 2)

###### Plot ACF for First and Second Order Differenced Series ######
# ACF plot for first-order differenced series
acf_plot_1 <- ggAcf(diff_1,50) +
  ggtitle("ACF of First-Order Differenced Series") +
  theme_minimal()

# ACF plot for second-order differenced series
acf_plot_2 <- ggAcf(diff_2,50) +
  ggtitle("ACF of Second-Order Differenced Series") +
  theme_minimal()

# Display both ACF plots side by side
acf_plot_1 / acf_plot_2
```

The ACF plots provide valuable insights into the differencing required to achieve stationarity:

1.  **First-Order Differencing**:

The ACF of the first-order differenced series shows significant positive autocorrelations that persist across many lags. This indicates that first-order differencing is **not sufficient** to make the series stationary, as the correlations do not decay quickly to zero.

2.  **Second-Order Differencing**:

The ACF of the second-order differenced series shows a much better result. The autocorrelations drop close to zero rapidly, with only a few spikes within the confidence intervals. This suggests that the second-order differencing has effectively removed the trend, making the series **closer to stationary**.

While the second-order differencing (d = 2) seems to provide a more stationary series, we should be cautious not to **over-difference**. To comply with the **principle of parsimony**—which favors simpler models with fewer parameters—we can explore ARIMA models using both **d = 1** and **d = 2**. Comparing model performance across different **parameter combinations** will help determine whether the additional differencing improves model accuracy or unnecessarily complicates the model.

### Step 3: Order of the AR term (p)?

The next step is to determine whether the model requires any **AutoRegressive (AR)** terms. This can be done by analyzing the **Partial Autocorrelation Function (PACF)** plot, which helps identify the appropriate number of AR terms to include in the model.



```{r, warning=FALSE, message=FALSE}

# Plot the Partial Autocorrelation Function (PACF) for Differenced Data
p1<-ggPacf(diff_1,50) +
  ggtitle("PACF of First Differenced Job Postings") +
  theme_minimal()

p2<-ggPacf(diff_2,50) +
  ggtitle("PACF of Second Differenced Job Postings") +
  theme_minimal()

p1/p2
```

Here you can observe, when **d=1**, there are high correlation at lags; **p = 0,1,2,3** (rest of the lags are too high). When **d=2**, there are high correlations at; **p =0,1,2.** 0 is a choice here since the correlation is not dying down.


### Step 4: Order of the MA term (q)

To determine the appropriate number of **Moving Average (MA)** terms for the model, we analyze the **Autocorrelation Function (ACF)** plot.


```{r, warning=FALSE, message=FALSE}

# Plot the Partial Autocorrelation Function (ACF) for Differenced Data
p1<-ggAcf(diff_1,50) +
  ggtitle("ACF of First Differenced Job Postings") +
  theme_minimal()

p2<-ggAcf(diff_2,50) +
  ggtitle("ACF of Second Differenced Job Postings") +
  theme_minimal()

p1/p2
```

Here, it is clear that d=2 provides better stationarity. Hence, at d=2, we can find correlation at lags; q=1 (rest of the lags are too high for parameters)

### Step 5: Parameter Tuning

Let's go throgh different parameter combinations to find the best model.

```{r, warning=FALSE, message=FALSE}

# Load necessary libraries
library(knitr)
library(kableExtra)


# Define parameter ranges
p_range <- 0:4
d_range <- 1:2
q_range <- 1  # Single value for q

# Calculate total combinations
n_combinations <- length(p_range) * length(d_range) * length(q_range)

# Create an empty matrix to store results
results_matrix <- matrix(NA, nrow = n_combinations, ncol = 6)

# Initialize index for matrix row
i <- 1

# Loop through combinations of ARIMA model parameters
for (d in d_range) {
  for (p in p_range) {
    q <- q_range

    # Fit ARIMA model with specified (p,d,q)
    model <- Arima(ts_indeed, order = c(p, d, q), include.drift = TRUE)

    # Store model parameters and AIC/BIC/AICc values in matrix
    results_matrix[i, ] <- c(p, d, q, model$aic, model$bic, model$aicc)

    # Increment row index
    i <- i + 1
  }
}

# Convert matrix to data frame
results_df <- as.data.frame(results_matrix)
colnames(results_df) <- c("p", "d", "q", "AIC", "BIC", "AICc")

# Find the row with the lowest AIC
highlight_row <- which.min(results_df$AIC)

# Generate kable table with highlighting for the row with the lowest AIC
knitr::kable(results_df, align = 'c', caption = "Comparison of ARIMA Models") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(highlight_row, bold = TRUE, background = "#FFFF99")  # Highlight row in yellow
```

Here, it indicates that **ARIMA(1,1,1)** model has the lowest AIC and BIC values.

However, Let's check with `auto.arima()`:

```{r, warning=FALSE, message=FALSE}

auto.arima(ts_indeed)
```

This indicates **ARIMA(4,2,2)** model. Therefore, I will run the parameter combination again with adding **p=4 and q=2**.

```{r, warning=FALSE, message=FALSE}


# Load necessary libraries
library(knitr)
library(kableExtra)
library(forecast)

# Create an empty matrix to store results
results_matrix <- matrix(rep(NA, 6 * 20), nrow = 20)

# Initialize index for matrix row
i <- 1

# Loop through ARIMA model parameters: d = 1,2; p = 0:4; q = 1,2
for (d in 1:2) {
  for (p in 0:4) {
    for (q in 1:2) {
      
      # Ensure 'ts_indeed' is a univariate time series by selecting the correct column
      model <- Arima(ts_indeed, order = c(p, d, q), include.drift = TRUE)
      
      # Store model parameters and AIC/BIC/AICc values in matrix
      results_matrix[i, ] <- c(p, d, q, model$aic, model$bic, model$aicc)
      
      # Increment row index
      i <- i + 1
    }
  }
}

# Convert matrix to data frame
results_df <- as.data.frame(results_matrix)
colnames(results_df) <- c("p", "d", "q", "AIC", "BIC", "AICc")

# Find the row with the minimum AIC
highlight_row <- which.min(results_df$AIC)

# Generate kable table with highlighting for the row with the minimum AIC
knitr::kable(results_df, align = 'c', caption = "Comparison of ARIMA Models") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(highlight_row, bold = TRUE, background = "#FFFF99")  # Highlight row in yellow

```

It is indeed that the model **ARIMA(4,2,2)** has the lowest AIC value. However, **ARIMA(4,1,2)** has the lowest BIC value.

### Step 6: Model Selection - Model Diagnostics

We have several choices for our models. Let's check the model diagnostics to find the best model.

The Models chosen by the above analysis:

-   ARIMA(1,1,1)
-   ARIMA(4,1,2)
-   ARIMA(4,2,2)

**ARIMA(1,1,1)**

```{r, warning=FALSE, message=FALSE}


# Set seed for reproducibility
set.seed(345)

##### Capture ARIMA model output for diagnostics #####

# Example model diagnostics for ARIMA(1,1,1)
model_output <- capture.output(sarima(ts_indeed, 1, 1, 1))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")

```

The **Residual Plot** shows nearly consistent fluctuation around zero, suggesting that the residuals are nearly stationary with a constant mean and finite variance over time.

The **Autocorrelation Function (ACF)** of the residuals reveals no significant autocorrelations except around lag 10, which is too high to include in the model.

The **Q-Q Plot** indicates that the residuals follow a near-normal distribution, with minor deviations at the tails, which is typical in time series data.

The **Ljung-Box Test** p-values remain mostly below the 0.05 significance level, implying some significant autocorrelations left in the residuals and concluding that model improvements may necessary.

**Coefficient Significance**: All model coefficients are significant for the ARIMA(1,1,1) model.

**ARIMA(4,1,2)**

```{r, warning=FALSE, message=FALSE}


# Set seed for reproducibility
set.seed(345)

##### Capture ARIMA(4,1,2) model output for diagnostics #####

# Fit ARIMA(4,1,2) model
model_output <- capture.output(sarima(ts_indeed, 4, 1, 2))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")

```

The **Residual Plot** shows nearly consistent fluctuation around zero, suggesting that the residuals are nearly stationary with a constant mean and finite variance over time.

The **Autocorrelation Function (ACF)** of the residuals reveals significant autocorrelations around lag 2 and high order lags, which are too high to include in the model.

The **Q-Q Plot** indicates that the residuals follow a near-normal distribution, with minor deviations at the tails, which is typical in time series data.

The **Ljung-Box Test** p-values remain below the 0.05 significance level, implying some significant autocorrelations left in the residuals and concluding that model improvements may necessary.

**Coefficient Significance**: All model coefficients are significant for the ARIMA(4,1,2) model.

**ARIMA(4,2,2)**

```{r, warning=FALSE, message=FALSE}


# Set seed for reproducibility
set.seed(345)

##### Capture ARIMA(4,2,2) model output for diagnostics #####

# Fit ARIMA(4,2,2) model
model_output <- capture.output(sarima(ts_indeed, 4, 2, 2))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")
```

The **Residual Plot** shows nearly consistent fluctuation around zero(better than the two plots above), suggesting that the residuals are nearly stationary with a constant mean and finite variance over time.

The **Autocorrelation Function (ACF)** of the residuals still shows some significant autocorrelations at high lags, which is too high to include in the model.

The **Q-Q Plot** indicates that the residuals follow a near-normal distribution, with minor deviations at the tails, which is typical in time series data.

The **Ljung-Box Test** p-values remain below the 0.05 significance level, implying some significant autocorrelations left in the residuals and concluding that model improvements may necessary.

**Coefficient Significance**: All model coefficients are significant.

#### Conclusion:

Model diagnostics were similar with all the above models. Therefore, we will choose the model with lowest AIC which is **ARIMA(4,2,2)**.

#### Model fitting

```{r, warning=FALSE, message=FALSE}


# Fit ARIMA(4,2,2) model
fit <- Arima(ts_indeed, order = c(4, 2, 2), include.drift = FALSE)

# Display model summary
summary(fit)
```

#### Model Equation

A process $x_t$ is said to be $\operatorname{ARIMA}(p, d, q)$ if

$$
\nabla^d x_t=(1-B)^d x_t
$$

Where;

$$
\phi(B)=1+0.76 B+1.11 B^2+ 0.45 B^3 + 0.29 B^4
$$

$$
\theta(B)=1+ 0.44 B+ 0.98 B^2
$$



### Step 7: Model Forecasting

Forecasting is the final and most crucial step in time series modeling, as the primary goal of building these models is to generate accurate predictions of future values. 

```{r, warning=FALSE, message=FALSE}

# Forecast the next 365 periods
forecast_result <- forecast(fit, h = 365)

# Display forecast accuracy
accuracy(forecast_result)

# Plot the forecast
autoplot(forecast_result) +
  labs(title = "ARIMA(4,2,2) Forecast",
       x = "Time",
       y = "Predicted Values") +
  theme_minimal()
```

The forecast for job postings over the next **year (approximately 365 days)** suggests a potential decline in the number of new postings. This downward trend could be attributed to **seasonal hiring patterns**, where many **summer and fall positions are typically posted earlier in the year, particularly in January**. Another possible explanation could be a broader **market trend indicating a slowdown in job availability**.

The **confidence intervals** shown in the shaded blue area represent the range within which the actual job postings are expected to fall. The **widening of these intervals** as we move further into the forecast period reflects increasing uncertainty. While the central forecast suggests a decline, the broader confidence range indicates that there is still some possibility for fluctuations—either a steeper decline or a stabilization in job postings. This uncertainty highlights the need to monitor the job market closely over the coming months to determine whether this trend is seasonal or indicative of a larger economic shift.

## Benchmark Methods

For **univariate time series forecasting**, establishing benchmarks is straightforward. At a minimum, forecasts should be compared against a **naive method** and a standard approach like an **ARIMA model** to evaluate the effectiveness of new techniques.

[Source](https://robjhyndman.com/hyndsight/benchmarks/)



By comparing new forecasting models against these baseline methods, we can better understand whether the proposed techniques provide meaningful improvements.


Let's go back to our example on the job postings at indeed.com.

```{r, warning=FALSE, message=FALSE}



# Fit models individually and check residuals
f_mean <- meanf(ts_indeed, h = 200)
head(f_mean$mean) #gives the forecasted values

mean(ts_indeed)

f_naive <- naive(ts_indeed, h = 200)
#checkresiduals(f_naive)

f_drift <- rwf(ts_indeed, drift = TRUE, h = 200)
checkresiduals(f_drift)
```


```{r, warning=FALSE, message=FALSE}


# Plot forecasts using Mean, Naïve, Drift methods, and ARIMA fit
autoplot(ts_indeed) +
  autolayer(meanf(ts_indeed, h = 365), series = "Mean", PI = FALSE) +
  autolayer(naive(ts_indeed, h = 365), series = "Naïve", PI = FALSE) +
  autolayer(rwf(ts_indeed, drift = TRUE, h = 365), series = "Drift", PI = FALSE) +
  autolayer(forecast(fit, h = 365), series = "ARIMA Fit", PI = FALSE) +
  ggtitle("Job Postings Forecast") +
  xlab("Date") + ylab("Number of Job Postings") +
  guides(colour = guide_legend(title = "Forecast Methods")) +
  theme_minimal()



```

In plotly so we can zoom the forecasts:

```{r, warning=FALSE, message=FALSE}



# Generate forecasts
mean_forecast <- meanf(ts_indeed, h = 365)
naive_forecast <- naive(ts_indeed, h = 365)
drift_forecast <- rwf(ts_indeed, drift = TRUE, h = 365)
arima_forecast <- forecast(fit, h = 365)

# Convert forecasts to data frames
mean_df <- data.frame(Date = time(mean_forecast$mean), Mean = as.numeric(mean_forecast$mean))
naive_df <- data.frame(Date = time(naive_forecast$mean), Naive = as.numeric(naive_forecast$mean))
drift_df <- data.frame(Date = time(drift_forecast$mean), Drift = as.numeric(drift_forecast$mean))
arima_df <- data.frame(Date = time(arima_forecast$mean), ARIMA_Fit = as.numeric(arima_forecast$mean))

# Original data
ts_indeed_df <- data.frame(Date = time(ts_indeed), Job_Postings = as.numeric(ts_indeed))

# Create Plotly plot
plot_ly() %>%
  add_lines(data = ts_indeed_df, x = ~Date, y = ~Job_Postings, name = 'Original Data', line = list(color = 'black')) %>%
  add_lines(data = mean_df, x = ~Date, y = ~Mean, name = 'Mean Forecast', line = list(color = 'blue')) %>%
  add_lines(data = naive_df, x = ~Date, y = ~Naive, name = 'Naïve Forecast', line = list(color = 'red')) %>%
  add_lines(data = drift_df, x = ~Date, y = ~Drift, name = 'Drift Forecast', line = list(color = 'green')) %>%
  add_lines(data = arima_df, x = ~Date, y = ~ARIMA_Fit, name = 'ARIMA Fit', line = list(color = 'purple')) %>%
  layout(title = 'Job Postings Forecast',
         xaxis = list(title = 'Date'),
         yaxis = list(title = 'Number of Job Postings'),
         legend = list(title = list(text = 'Forecast Methods')))

```

By zooming n, it is very clear that the ARIMA model does a better method than the basic bench mark methods.

## fpp3 package

`fpp3` package has a new tool for fitting models automatically similar to `auto.arima()` but the model procedure is different in the `fpp3` package.

```{r, warning=FALSE, message=FALSE}

# Load necessary libraries
library(tsibble)
library(fable)
library(feasts)
library(dplyr)

# Ensure 'Date' is in date format
indeed_data$Date <- as.Date(indeed_data$Date)

# Convert to tsibble
ts_indeed2 <- indeed_data %>%
  as_tsibble(index = Date)

# Fit ARIMA model
fit <- ts_indeed2 %>%
  model(ARIMA(job_postings))

# Display model summary
report(fit)
```

This is a seasonal model. This could be better considering the data was daily and it was indicated that the Frequency was Daily,7-Day [source](https://fred.stlouisfed.org/series/IHLIDXUS). We can revisit in the next chapter. 

Check the model diagnostics:

```{r, warning=FALSE, message=FALSE}


# Set seed for reproducibility
set.seed(345)

##### Capture ARIMA(2,2,2)(1,0,1)[7] model output for diagnostics #####

# Fit seasonal ARIMA model
model_output <- capture.output(sarima(ts_indeed, 2, 2, 2, 1, 0, 1, 7))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")
```

Still it dosen't make a big difference but seasonal ar1 coefficient is not significant here. However, this model has a lower AIC value than the ARIMA(4,2,2) model.

```{r, warning=FALSE, message=FALSE}

# Load necessary library
library(forecast)

# Fit ARIMA(2,2,2)(1,0,1)[7] model
fit <- Arima(ts_indeed, order = c(2, 2, 2), seasonal = list(order = c(1, 0, 1), period = 7), include.drift = FALSE)

# Display model summary
summary(fit)
```
```{r, warning=FALSE, message=FALSE}


# Generate the forecast
forecast_result <- forecast(fit, h = 365)

# Plot the forecast
autoplot(forecast_result) +
  labs(title = "ARIMA(2,2,2)(1,0,1)[7] Forecast",
       x = "Time",
       y = "Predicted Job Postings") +
  theme_minimal()
```


## Prophet Model

Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.

Prophet is open source software released by Facebook’s Core Data Science team. It is available for download on CRAN and PyPI.

[source](https://facebook.github.io/prophet/)

### In R

[Read More 1](https://facebook.github.io/prophet/docs/quick_start.html#r-api)

[Read More 2](https://mode.com/example-gallery/forecasting_prophet_r_cookbook)

```{r, warning=FALSE, message=FALSE}


# Load required libraries
library(prophet)


# Prepare the dataset for Prophet
job_postings_data <- indeed_data %>% 
  select(Date, job_postings) %>% 
  rename(ds = Date, y = job_postings)

# Initialize and fit the Prophet model
prophet_model <- prophet(job_postings_data)

# Extend the forecast horizon by 365 days
future_dates <- make_future_dataframe(prophet_model, periods = 365)

# Generate future predictions
predictions <- predict(prophet_model, future_dates)

# Visualize the forecast
plot(prophet_model, predictions)

```

This forecasting looks better than the simple ARIMA or the SARIMA model. We will discuss more examples later.


## Financial Time Series: Apple Stock prices

We will use Apple stock prices as our example dataset.

```{r, warning=FALSE, message=FALSE}

###### Load Apple Stock Data from Yahoo Finance ######
AAPL <- getSymbols("AAPL", auto.assign = FALSE, from = "1980-01-01", src = "yahoo")

###### Convert to Data Frame and Add Date Column ######
AAPL <- data.frame(AAPL)
AAPL <- data.frame(AAPL, rownames(AAPL))

###### Rename the Date Column ######
colnames(AAPL)[7] <- "date"

###### Convert Date Column to Date Format ######
AAPL$date <- as.Date(AAPL$date, "%Y-%m-%d")

###### Create Data Frame with Original and Log-Transformed Adjusted Close Prices ######
data <- data.frame(AAPL$date, AAPL$AAPL.Adjusted, log(AAPL$AAPL.Adjusted))
colnames(data) <- c("date", "AAPL", "log.AAPL")

###### Plot Original and Log-Transformed Adjusted Close Prices ######
ggplot(data) +
  geom_line(aes(x = date, y = AAPL, color = "Adjusted Close")) +
  geom_line(aes(x = date, y = log.AAPL, color = "Log Adjusted Close")) +
  labs(title = "Apple Stock Prices (Adjusted & Log-Transformed)",
       x = "Date",
       y = "Price",
       color = "Legend") +
  theme_minimal()

```

`AAPL` is the ticker symbol for Apple Inc.'s stock, and we have retrieved its historical prices from Yahoo Finance.

Upon plotting the data, we observe **heteroscedasticity**, where the variability increases over time. This non-constant variance can negatively impact model accuracy. To mitigate this, we apply a **log transformation**, which helps stabilize the variance.

The log-transformed data reduces heteroscedasticity, providing a more consistent trend and making it more suitable for reliable model fitting.

```{r, warning=FALSE, message=FALSE}

###### Convert to Time Series Object ######
ts_AAPL <- ts(data$AAPL, 
              start = decimal_date(as.Date("1980-12-12")), 
              frequency = 252)  # Approx. number of trading days in a year

# Plot the Autocorrelation Function (ACF)
ggAcf(ts_AAPL,50) +
  ggtitle("Autocorrelation Function of Apple Stock Prices") +
  theme_minimal()
```

To assess serial correlation, we use the Autocorrelation Function (ACF) plot. The ACF plot shows clear signs of high serial correlation, indicating that past values significantly influence future values. This indicates **differencing** is needed to achieve stationarity.

```{r, warning=FALSE, message=FALSE}

# Lag plot to visualize patterns at different lags
gglagplot(ts_AAPL, do.lines = FALSE) +
  ggtitle("Lag Plot of Apple Stock Prices") +
  theme_minimal()

# Plot the Time Series with Moving Averages
autoplot(ts_AAPL, series = "Apple Adjusted Close") +
  autolayer(ma(ts_AAPL, 200), series = "200-Day Moving Average") +
  autolayer(ma(ts_AAPL, 500), series = "500-Day Moving Average") +
  labs(title = "Apple Stock Prices with Moving Averages",
       x = "Year",
       y = "Adjusted Close Price",
       color = "Legend") +
  theme_minimal()
```

Applying a high moving average (MA) helps smooth out short-term fluctuations, making long-term trends and patterns more visible. In this case, the moving average highlights a substantial increase in Apple’s stock prices, particularly after the year 2000.

### Log transformation

```{r, warning=FALSE, message=FALSE}
###### Load Required Libraries ######

library(patchwork)


###### Create Data Frame with Original and Log-Transformed Adjusted Close Prices ######
data <- data.frame(AAPL$date, AAPL$AAPL.Adjusted, log(AAPL$AAPL.Adjusted))
colnames(data) <- c("date", "AAPL", "log.AAPL")

###### Convert to Time Series Object ######
ts_AAPL <- ts(data$AAPL, 
              start = decimal_date(as.Date(min(data$date))), 
              frequency = 12)  # Assuming monthly data

ts_log_AAPL <- ts(data$log.AAPL, 
                  start = decimal_date(as.Date(min(data$date))), 
                  frequency = 12)

###### Differencing the Data ######
diff_AAPL <- diff(ts_AAPL)
diff_log_AAPL <- diff(ts_log_AAPL)

# Create plots for differenced data
p1 <- ggplot() +
  geom_line(aes(x = time(diff_AAPL), y = diff_AAPL), color = "blue") +
  labs(title = "Differenced Apple Stock Prices",
       x = "Time",
       y = "Differenced Prices") +
  theme_minimal()

p2 <- ggplot() +
  geom_line(aes(x = time(diff_log_AAPL), y = diff_log_AAPL), color = "red") +
  labs(title = "Differenced Log-Transformed Apple Stock Prices",
       x = "Time",
       y = "Differenced Log Prices") +
  theme_minimal()

# Combine plots using patchwork
p1 / p2
```

It is clear that the data needs to be transformed before fitting model.

#### Differencing - parameter selection

```{r, warning=FALSE, message=FALSE}
###### Differencing the Log-Transformed Data ######
diff_log_AAPL <- diff(ts_log_AAPL)
diff2_log_AAPL <- diff(ts_log_AAPL, differences = 2)

# ACF Plots for Differenced Log-Transformed Data
acf_plot1 <- ggAcf(diff_log_AAPL) +
  labs(title = "ACF of First Differenced Log-Transformed Apple Stock Prices") +
  theme_minimal()

acf_plot2 <- ggAcf(diff2_log_AAPL) +
  labs(title = "ACF of Second Differenced Log-Transformed Apple Stock Prices") +
  theme_minimal()

# Combine ACF Plots using patchwork
acf_plot1 / acf_plot2

```
First order differencing is sufficient.

```{r, warning=FALSE, message=FALSE}
###### ACF and PACF Plots for First Differenced Log-Transformed Data ######
acf_plot <- ggAcf(diff_log_AAPL) +
  labs(title = "ACF of First Differenced Log-Transformed Apple Stock Prices") +
  theme_minimal()

pacf_plot <- ggPacf(diff_log_AAPL) +
  labs(title = "PACF of First Differenced Log-Transformed Apple Stock Prices") +
  theme_minimal()

# Combine ACF and PACF Plots using patchwork
acf_plot / pacf_plot
```
d=1, p=2:4, q = 2:4

```{r, warning=FALSE, message=FALSE}
###### Load Necessary Libraries ######
library(knitr)
library(kableExtra)
library(forecast)

###### Create an Empty Matrix to Store Results ######
results_matrix <- matrix(rep(NA, 6 * 9), nrow = 9)

###### Initialize Index for Matrix Row ######
i <- 1

###### Loop through ARIMA Model Parameters: d = 1; p = 2:4; q = 2:4 ######
for (p in 2:4) {
  for (q in 2:4) {
    
    # Fit ARIMA model
    model <- Arima(diff_log_AAPL, order = c(p, 1, q), include.drift = TRUE)
    
    # Store model parameters and AIC/BIC/AICc values in matrix
    results_matrix[i, ] <- c(p, 1, q, model$aic, model$bic, model$aicc)
    
    # Increment row index
    i <- i + 1
  }
}

###### Convert Matrix to Data Frame ######
results_df <- as.data.frame(results_matrix)
colnames(results_df) <- c("p", "d", "q", "AIC", "BIC", "AICc")

###### Find the Row with the Minimum AIC ######
highlight_row <- which.min(results_df$AIC)

###### Generate kable Table with Highlighting for the Row with the Minimum AIC ######
knitr::kable(results_df, align = 'c', caption = "Comparison of ARIMA Models") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(highlight_row, bold = TRUE, background = "#FFFF99")  # Highlight row in yellow


```
ARIMA(3,1,2) is a good model.

Let's check `auto.arima()`

```{r}
auto.arima(ts_log_AAPL)
```
This suggests ARIMA(4,0,0)(1,0,0)[12].

Let's check `fpp3` package:

```{r}
# Load necessary libraries
library(tsibble)
library(fable)
library(feasts)
library(dplyr)

###### Prepare the Log-Transformed Apple Data ######
# Ensure 'Date' is in date format
AAPL$date <- as.Date(AAPL$date)

# Create a data frame with log-transformed adjusted close prices
apple_data <- AAPL %>% 
  select(date, AAPL.Adjusted) %>% 
  mutate(log_AAPL = log(AAPL.Adjusted))

# Convert to tsibble and fill implicit gaps
ts_apple <- apple_data %>% 
  as_tsibble(index = date) %>%
  fill_gaps()

###### Fit ARIMA Model on Log-Transformed Data ######
fit <- ts_apple %>% 
  model(ARIMA(log_AAPL))

###### Display Model Summary ######
report(fit)

```
This gives me a constant model which is not a good model.

#### Model Comparison

**ARIMA(3,1,2)**

```{r, warning=FALSE, message=FALSE}


# Set seed for reproducibility
set.seed(345)

##### Capture ARIMA(3,1,2) model output for diagnostics #####

# Fit ARIMA(4,2,2) model
model_output <- capture.output(sarima(ts_log_AAPL, 3, 1, 2))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")
```

The **Residual Plot** shows nearly consistent fluctuation around zero, but we see some clustering, suggesting that the financial models would be better for this data.

The **Autocorrelation Function (ACF)** of the residuals shows mostly independence..

The **Q-Q Plot** indicates that the residuals follow a somewhat-normal distribution, with minor deviations at the tails, which indicate we need model improvements.

The **Ljung-Box Test** p-values remain mostly below the 0.05 significance level, implying some significant autocorrelations left in the residuals and concluding that model improvements may necessary.

**Coefficient Significance**: ar2 and ma2 coefficients are not significant.

**ARIMA(4,0,0)(1,0,0)[12]**

```{r, warning=FALSE, message=FALSE, eval=FALSE}
###### Set Seed for Reproducibility ######
set.seed(345)

###### Capture ARIMA Model Output for Diagnostics ######

# Model diagnostics for ARIMA(4,0,0)x(1,0,0)[12]
model_output <- capture.output(sarima(ts_log_AAPL, p = 4, d = 0, q = 0, P = 1, D = 0, Q = 0, S = 12))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")

```

This gives the below error message stating that it has non-stationary AR part which means this is not a good fit for the data:

"Error in arima(xdata, order = c(p, d, q), seasonal = list(order = c(P,  : 
  non-stationary AR part from CSS"


#### Model Forecast

so far ARIMA(3,1,2) is better.

```{r}
fit <- Arima(ts_log_AAPL, order = c(3, 1, 2), include.drift = FALSE)

# Display model summary
summary(fit)
```
#### Model Equation

A process $x_t$ is said to be $\operatorname{ARIMA}(p, d, q)$ if

$$
\nabla^d x_t=(1-B)^d x_t
$$
Where;

$$
\phi(B)=1+0.51 B+0.16 B^2+ 0.04 B^3 
$$

$$
\theta(B)=1+ 0.52 B+ 0.14 B^2
$$
#### Model Forecast

```{r}
# Forecast the next 365 periods
forecast_result <- forecast(fit, h = 365)

# Display forecast accuracy
accuracy(forecast_result)

# Plot the forecast
autoplot(forecast_result) +
  labs(title = "ARIMA(3,1,2) Forecast",
       x = "Time",
       y = "Predicted Values") +
  theme_minimal()
```

```{r}

###### Plot Forecasts Using Mean, Naïve, Drift Methods, and ARIMA Fit ######
autoplot(ts_log_AAPL) +
  autolayer(meanf(ts_log_AAPL, h = 365), series = "Mean", PI = FALSE) +
  autolayer(naive(ts_log_AAPL, h = 365), series = "Naïve", PI = FALSE) +
  autolayer(rwf(ts_log_AAPL, drift = TRUE, h = 365), series = "Drift", PI = FALSE) +
  autolayer(forecast(fit, h = 365), series = "ARIMA Fit", PI = FALSE) +
  ggtitle("Apple Stock Price Forecast (Log-Transformed)") +
  xlab("Date") + ylab("Log Adjusted Close Price") +
  guides(colour = guide_legend(title = "Forecast Methods")) +
  theme_minimal()

```

It looks like the drift model is catching the trend better than the ARIMA model. This means that this ARIMA model is not sufficient. Which is true. This is financial data. an ARCH/GARCH model needs to be fitted for this data.

# SARIMA Model

$$ARIMA(p,d,q)X(P,D,Q)_s$$

## Class Example

We will use [Egg Prices](https://fred.stlouisfed.org/series/APU0000708111) as our example dataset.

```{r, warning=FALSE, message=FALSE}


###### Load Egg Price Data and Rename Columns ######
eggs_data <- read.csv("eggs_price_2025.csv")
colnames(eggs_data) <- c("Date", "egg_prices")

###### Plot Original Data using Plotly ######
plot_ly(eggs_data, x = ~as.Date(Date), y = ~egg_prices, type = 'scatter', mode = 'lines',
        line = list(color = 'blue')) %>%
  layout(title = "Original Egg Prices",
         xaxis = list(title = "Date"),
         yaxis = list(title = "Egg Prices"))
```

Upon plotting the data, we observe **heteroscedasticity**, where the variability increases over time. This non-constant variance can negatively impact model accuracy. To mitigate this, we apply a **log transformation**, which helps stabilize the variance.

The log-transformed data reduces heteroscedasticity, providing a more consistent trend and making it more suitable for reliable model fitting.

To confirm, let's compare the logged-transformed data and the differenced data.

```{r, warning=FALSE, message=FALSE}

###### Plot Original and Log-Transformed Data using Plotly ######
eggs_data$log_egg_prices <- log(eggs_data$egg_prices)

plot_ly(eggs_data, x = ~as.Date(Date)) %>%
  add_lines(y = ~egg_prices, name = 'Original Prices', line = list(color = 'blue')) %>%
  add_lines(y = ~log_egg_prices, name = 'Log-Transformed Prices', line = list(color = 'red')) %>%
  layout(title = "Original vs Log-Transformed Egg Prices",
         xaxis = list(title = "Date"),
         yaxis = list(title = "Price"))
```

*Note:* We are currently working with a **univariate time series**, focusing solely on Eggs prices.

```{r, warning=FALSE, message=FALSE}

library(patchwork)
###### Convert to Time Series Object ######
ts_eggs <- ts(eggs_data$egg_prices, 
              start = decimal_date(as.Date(min(eggs_data$Date))), 
              frequency = 12)  # Assuming monthly data

ts_log_eggs <- ts(eggs_data$log_egg_prices, 
                  start = decimal_date(as.Date(min(eggs_data$Date))), 
                  frequency = 12)

###### Differencing the Data ######
diff_eggs <- diff(ts_eggs)
diff_log_eggs <- diff(ts_log_eggs)

# Create plots for differenced data
p1 <- ggplot() +
  geom_line(aes(x = time(diff_eggs), y = diff_eggs), color = "blue") +
  labs(title = "Differenced Egg Prices",
       x = "Time",
       y = "Differenced Prices") +
  theme_minimal()

p2 <- ggplot() +
  geom_line(aes(x = time(diff_log_eggs), y = diff_log_eggs), color = "red") +
  labs(title = "Differenced Log-Transformed Egg Prices",
       x = "Time",
       y = "Differenced Log Prices") +
  theme_minimal()

# Combine plots using patchwork
p1 / p2
```

It is clear from the above data that the log transformed data should be used.

#### Seasonality

Check the seasonality:

```{r, warning=FALSE, message=FALSE}

###### Decompose the Time Series and Plot ######
autoplot(decompose(ts_log_eggs)) +
  ggtitle("Decomposition of Log Transformed Egg Prices") +
  xlab("Date") +
  ylab("Value")
```

There is a clear seasonal component here.

Moreover, check the lag plots for seasonal correlation at lags 12, 24, 36, 48.

```{r, warning=FALSE, message=FALSE}

###### Plot Lag Plot using gglagplot ######
gglagplot(ts_log_eggs, do.lines = FALSE, set.lags = c(12, 24, 36, 48)) +
  ggtitle("Lag Plot of Log Transformed Egg Prices")
```

There seem to be correlation at seasonal lag 1 and 2.

```{r, warning=FALSE, message=FALSE}

###### Plot ACF of Log Transformed Egg Prices using ggAcf ######
ggAcf(ts_log_eggs,50) +
  ggtitle("ACF of Log Transformed Egg Prices")
```

However, the above ACF plot makes it a little hard to identify seasonal correlations. This difficulty may stem from the strong autocorrelation caused by the underlying trend in the data.


### Differencing the data

**Ordinary Differencing**

```{r, warning=FALSE, message=FALSE}

###### First and Second Order Differencing for Log Egg Prices ######
# First-order differencing
diff_log_1 <- diff(ts_log_eggs)

# Second-order differencing
diff_log_2 <- diff(ts_log_eggs, differences = 2)

###### Plot ACF for First and Second Order Differenced Log Series ######
# ACF plot for first-order differenced log series
acf_log_plot_1 <- ggAcf(diff_log_1, 50) +
  ggtitle("ACF of First-Order Differenced Log Series") +
  theme_minimal()

# ACF plot for second-order differenced log series
acf_log_plot_2 <- ggAcf(diff_log_2, 50) +
  ggtitle("ACF of Second-Order Differenced Log Series") +
  theme_minimal()

# Display both ACF plots side by side
acf_log_plot_1 / acf_log_plot_2

```
The above plots clearly indicate that first-order differencing is sufficient, while second-order differencing results in over-differencing. Additionally, strong seasonal correlations are evident at seasonal lags of 12, 24, 36, and so on.

**Seasonal Differencing**

```{r, warning=FALSE, message=FALSE}

###### Apply Only Seasonal Differencing (Lag = 12) ######
seasonal_only_diff <- diff(ts_log_eggs, lag = 12)

###### Plot ACF for the Only Seasonally Differenced Series ######
ggAcf(seasonal_only_diff) +
  ggtitle("ACF of Only Seasonally Differenced Log Egg Prices") +
  theme_minimal()
```
Seasonal differencing alone is insufficient, as significant autocorrelation from the underlying trend components remains in the series.

**Both Ordinary Differencing and Seasonal differencing**

```{r, warning=FALSE, message=FALSE}


###### Apply First-Order Differencing ######
first_diff <- diff(ts_log_eggs)

###### Apply Seasonal Differencing (Lag = 12) on Top of First-Order Differencing ######
seasonal_diff <- diff(first_diff, lag = 12)

###### Plot ACF and PACF for the Differenced Series ######
ggAcf(seasonal_diff) +
  ggtitle("ACF of Seasonally Differenced Log Egg Prices") +
  theme_minimal()
```
This series appears closer to weak stationarity. The ACF plot shows clear autocorrelations at lags q = 0,2, 4 and Q = 1.

Additionally, both first-order differencing (d = 1) and seasonal differencing (D = 1) have been applied to the data.

Let's check the PACF plot to check the AR parameters.

```{r, warning=FALSE, message=FALSE}


ggPacf(seasonal_diff) +
  ggtitle("PACF of Seasonally Differenced Log Egg Prices") +
  theme_minimal()
```
The PACF plot shows clear autocorrelations at lags p = 0,2,3 and P = 0,1,2.

### Parameter Search

```{r, warning=FALSE, message=FALSE}

###### Load Required Libraries ######
library(knitr)
library(kableExtra)


###### Initialize Variables ######
# Create an empty list to store models
SARIMA_fit <- list()

# Create an empty matrix to store results
results_matrix <- matrix(rep(NA, 9 * 4), nrow = 4)

# Initialize index for matrix row
cc <- 1

###### Loop through SARIMA Model Parameters ######
# Parameters: p = 2; d = 1; q = 2,4; P = 1,2; D = 1; Q = 1; s = 12
p <- 2
for (q in c(2, 4)) {
  for (P in 1:2) {
    Q <- 1
    
    # Fit SARIMA model
    model <- Arima(ts_log_eggs, order = c(p, 1, q), seasonal = c(P, 1, Q))
    
    # Store model in list
    SARIMA_fit[[cc]] <- model
    
    # Store model parameters and AIC/BIC/AICc values in matrix
    results_matrix[cc, ] <- c(p, 1, q, P, 1, Q, model$aic, model$bic, model$aicc)
    
    # Increment row index
    cc <- cc + 1
  }
}

###### Convert Matrix to Data Frame ######
results_df <- as.data.frame(na.omit(results_matrix))
colnames(results_df) <- c("p", "d", "q", "P", "D", "Q", "AIC", "BIC", "AICc")

###### Find the Row with the Minimum AIC ######
highlight_row <- which.min(results_df$AIC)

###### Generate kable Table with Highlighting for the Row with the Minimum AIC ######
knitr::kable(results_df, align = 'c', caption = "Comparison of SARIMA Models") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(highlight_row, bold = TRUE, background = "#FFFF99")

```

This shows that the lowest AIC and BIC is for ARIMA(2,1,1)x(1,1,1)[12].

I'm going to check with different parameters.

```{r, warning=FALSE, message=FALSE}

###### Define SARIMA Model Comparison Function ######
SARIMA.c = function(p1, p2, q1, q2, P1, P2, Q1, Q2, data) {
  
  # Set differencing orders and seasonal period
  d = 1
  D = 1
  s = 12
  
  # Initialize result storage
  i = 1
  results_matrix = matrix(NA, nrow = 100, ncol = 9)
  
  # Iterate over parameter ranges
  for (p in p1:p2) {
    for (q in q1:q2) {
      for (P in P1:P2) {
        for (Q in Q1:Q2) {
          
          # Apply parameter constraint to avoid overfitting
          if (p + d + q + P + D + Q <= 10) {
            
            # Fit SARIMA model
            model <- Arima(data, order = c(p, d, q), seasonal = c(P, D, Q))
            
            # Store parameters and model selection criteria
            results_matrix[i, ] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)
            i = i + 1
          }
        }
      }
    }
  }
  
  # Convert results to data frame and label columns
  results_df = as.data.frame(na.omit(results_matrix))
  names(results_df) = c("p", "d", "q", "P", "D", "Q", "AIC", "BIC", "AICc")
  
  return(results_df)
}

###### Run SARIMA Model Comparison ######
output = SARIMA.c(p1 = 0, p2 = 3, q1 = 0, q2 = 3, P1 = 0, P2 = 2, Q1 = 0, Q2 = 1, data = ts_log_eggs)

###### Identify Models with Minimum AIC and BIC ######
minaic = output[which.min(output$AIC), ]
minbic = output[which.min(output$BIC), ]

###### Display Best Models Based on AIC and BIC ######
minaic
minbic

```

This results in ARIMA(3,1,2)x(2,1,1)[12] and ARIMA(0,1,2)x(0,1,1)[12].


#### Checking with auto.arima()

```{r, warning=FALSE, message=FALSE}

auto.arima(ts_log_eggs)
```
This shows the good fit is ARIMA(3,1,2)x(2,0,0)[12].


### Model Diagnostics

We have several choices for our models. Let's check the model diagnostics to find the best model.

The Models chosen by the above analysis:

-   ARIMA(2,1,1)x(1,1,1)[12]
-   ARIMA(3,1,2)x(2,0,0)[12]
-   ARIMA(3,1,2)x(2,1,1)[12]
-   ARIMA(0,1,2)x(0,1,1)[12]


**ARIMA(2,1,1)x(1,1,1)[12]**

```{r, warning=FALSE, message=FALSE}

###### Set Seed for Reproducibility ######
set.seed(345)

###### Capture ARIMA Model Output for Diagnostics ######

# Model diagnostics for ARIMA(2,1,1)x(1,1,1)[12]
model_output <- capture.output(sarima(ts_log_eggs, 2, 1, 1, 1, 1, 1, 12))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")

```

The **Residual Plot** shows nearly consistent fluctuation around zero, suggesting that the residuals are nearly stationary with a constant mean and finite variance over time.

The **Autocorrelation Function (ACF)** of the residuals reveals no significant autocorrelations indicating a good model.

The **Q-Q Plot** indicates that the residuals follow a near-normal distribution, with minor deviations at the tails, which is typical in time series data.

The **Ljung-Box Test** p-values remain mostly above the 0.05 significance level, implying a nearly good fit.

**Coefficient Significance**: Here coefficients for ar1, ma1, sar1 are not significant. This may question about this model being a good fit based on this results.


**ARIMA(3,1,2)x(2,0,0)[12]**

```{r, warning=FALSE, message=FALSE}


###### Load Necessary Libraries ######
library(astsa)

###### Set Seed for Reproducibility ######
set.seed(345)

###### Capture ARIMA Model Output for Diagnostics ######

# Model diagnostics for ARIMA(3,1,2)x(2,0,0)[12]
model_output <- capture.output(sarima(ts_log_eggs, 3, 1, 2, 2, 0, 0, 12))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")
```

The **Residual Plot** shows nearly consistent fluctuation around zero, suggesting that the residuals are nearly stationary with a constant mean and finite variance over time.

The **Autocorrelation Function (ACF)** of the residuals reveals no significant autocorrelations indicating a good model.

The **Q-Q Plot** indicates that the residuals follow a near-normal distribution, with minor deviations at the tails, which is typical in time series data.

The **Ljung-Box Test** p-values remain mostly above the 0.05 significance level, implying a nearly good fit.

**Coefficient Significance**: Here coefficients for ar2, ar3, sar2 are not significant. This may question about this model being a good fit based on this results.

**ARIMA(3,1,2)x(2,1,1)[12]**

```{r, warning=FALSE, message=FALSE}




###### Set Seed for Reproducibility ######
set.seed(345)

###### Capture ARIMA Model Output for Diagnostics ######

# Model diagnostics for ARIMA(3,1,2)x(2,1,1)[12]
model_output <- capture.output(sarima(ts_log_eggs, 3, 1, 2, 2, 1, 1, 12))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")

```


**ARIMA(0,1,2)x(0,1,1)[12]**

```{r, warning=FALSE, message=FALSE}



###### Set Seed for Reproducibility ######
set.seed(345)

###### Capture ARIMA Model Output for Diagnostics ######

# Model diagnostics for ARIMA(0,1,2)x(0,1,1)[12]
model_output <- capture.output(sarima(ts_log_eggs, 0, 1, 2, 0, 1, 1, 12))

# Find the line numbers dynamically based on a keyword
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

# Print the relevant section automatically
cat(model_output[start_line:end_line], sep = "\n")
```

Comparing all the model diagnostic models and lower AIC values, we will choose **ARIMA(3,1,2)x(2,1,1)[12]**.

#### Fit the model

```{r, warning=FALSE, message=FALSE}


###### Fit the Final ARIMA Model ######
# Based on diagnostics and AIC values, ARIMA(3,1,2)x(2,1,1)[12] was selected
fit <- Arima(ts_log_eggs, order = c(3, 1, 2), seasonal = c(2, 1, 1))

###### Display Model Summary ######
summary(fit)
```

#### Forecaseting

```{r, warning=FALSE, message=FALSE}

###### Forecast the Next 100 Periods ######
forecast_result <- forecast(fit, h = 120)

###### Display Forecast Accuracy ######
accuracy(forecast_result)

###### Plot the Forecast ######
autoplot(forecast_result) +
  labs(title = "ARIMA(3,1,2)x(2,1,1)[12] Forecast",
       x = "Time",
       y = "Predicted Log Egg Prices") +
  theme_minimal()
```

#### Benchmark Methods

```{r, warning=FALSE, message=FALSE}

###### Forecast Comparison Plot ######
autoplot(ts_log_eggs) +
  autolayer(meanf(ts_log_eggs, h = 120), series = "Mean", PI = FALSE) +
  autolayer(naive(ts_log_eggs, h = 120), series = "Naïve", PI = FALSE) +
  autolayer(snaive(ts_log_eggs, h = 120), series = "SNaïve", PI = FALSE) +
  autolayer(rwf(ts_log_eggs, h = 120, drift = TRUE), series = "Drift", PI = FALSE) +
  autolayer(forecast(fit, h = 120), series = "SARIMA Fit", PI = FALSE) +
  guides(colour = guide_legend(title = "Forecast Methods")) +
  ggtitle("Forecast Comparison for Log Transformed Egg Prices") +
  ylab("Log Egg Prices") +
  xlab("Time")
```

Based on the benchmark methods it is clear that the SARIMA model was able to catch the trend in the egg prices.

#### Original Vs. Fitted Values

**For the log transformed data**

```{r, warning=FALSE, message=FALSE}


###### Forecast the Next 365 Periods ######
forecast_result <- forecast(fit, h = 365)

###### Display Forecast Accuracy ######
accuracy(forecast_result)

###### Plot Original Data vs Fitted Values ######
autoplot(ts_log_eggs, series = "Original Data") +
  autolayer(forecast_result$fitted, series = "Fitted Values", PI = FALSE) +
  labs(title = "Original Data vs Fitted Values",
       x = "Time",
       y = "Log Egg Prices") +
  theme_minimal() +
  guides(colour = guide_legend(title = "Series"))

```

**For the original data**

```{r, warning=FALSE, message=FALSE}



###### Forecast the Next 365 Periods ######
forecast_result <- forecast(fit, h = 365)

###### Display Forecast Accuracy ######
accuracy(forecast_result)

###### Plot Original Egg Prices vs Fitted Values ######
# Ensure Date is in Date format
eggs_data$Date <- as.Date(eggs_data$Date)

# Convert to time series format
start_year <- as.numeric(format(min(eggs_data$Date), "%Y"))
start_month <- as.numeric(format(min(eggs_data$Date), "%m"))

egg_prices_ts <- ts(eggs_data$egg_prices, start = c(start_year, start_month), frequency = 12)
fitted_ts <- ts(exp(forecast_result$fitted), start = c(start_year, start_month), frequency = 12)

# Plot
autoplot(egg_prices_ts, series = "Original Data") +
  autolayer(fitted_ts, series = "Fitted Values", PI = FALSE) +
  labs(title = "Original Egg Prices vs Fitted Values",
       x = "Time",
       y = "Egg Prices") +
  theme_minimal() +
  guides(colour = guide_legend(title = "Series"))




```


Very close prediction.

### Prophet model

Remember the prophet model works better when there is strong seasonality.

```{r, warning=FALSE, message=FALSE}

###### Load Required Libraries ######
library(prophet)
library(dplyr)

###### Prepare the Dataset for Prophet ######
# Convert the log-transformed egg prices data for Prophet
eggs_data_prophet <- eggs_data %>% 
  select(Date, log_egg_prices) %>% 
  rename(ds = Date, y = log_egg_prices)

###### Initialize and Fit the Prophet Model ######
prophet_model <- prophet(eggs_data_prophet)

###### Extend the Forecast Horizon by 365 Days ######
future_dates <- make_future_dataframe(prophet_model, periods = 365)

###### Generate Future Predictions ######
predictions <- predict(prophet_model, future_dates)

###### Visualize the Forecast ######
plot(prophet_model, predictions) +
  labs(title = "Prophet Forecast for Log Egg Prices",
       x = "Date",
       y = "Log Egg Prices")

```



## Example 2:

US monthly natural gas consumption: 2000 - 2019. Units: Billion Cubic Feet

a. TS plot and the ACF

```{r}

###### Plot US Monthly Natural Gas Consumption ######
autoplot(USgas) +
  ggtitle("US Monthly Natural Gas Consumption") +
  xlab("Year") + 
  ylab("Gas Consumption") +
  theme_minimal()

###### ACF Plot Using Base R ######
acf(USgas, main = "ACF of US Monthly Natural Gas Consumption")

###### ACF Plot Using ggAcf ######
ggAcf(USgas, lag.max = 40) +
  ggtitle("ACF of US Monthly Natural Gas Consumption (40 Lags)") 
  
```

you can see the difference of the ACF plot when using `ggAcf()` and `acf()` function. When you use `ggAcf()`,  the seasonal lags are at $12,24,36..$ but `acf()` indicate $1,2,..$ for seasonal lags and decimal values for ordinary lags.

b. Lag Plot

```{r}
########## Interactive plots#########
ts_lags(USgas,lags=c(12, 24, 36, 48)) 

#ts_lags(USgas, lags = c(12, 24, 36, 48))
######################################
gglagplot(USgas, do.lines=FALSE, set.lags = c(12, 24, 36, 48))+ggtitle("US monthly natural gas consumption") 

```

Apparent seasonal correlation can be seen by the positive correlation at seasonal lags 12,24,36,48..

c. Decomposing

We are using `decompose()` function to look at the seasonal component.

```{r}
dec2=decompose(USgas,type = c("additive", "multiplicative"))
plot(dec2)
```

d. Differencing

```{r, warning=FALSE, message=FALSE}

str(USgas) # this is already time series

USgas %>% diff() %>% ggtsdisplay() #first ordinary differencing

USgas %>% diff(lag=12) %>% ggtsdisplay() #first seasonal differencing

USgas %>% diff(lag=12) %>% diff() %>% ggtsdisplay() #do both
```
You can see that the first ordinary differencing is not enough because we can clearly see the seasonal correlation. Therefore, we need to proceed with the seasonal differencing.

Second set of plots : only seasonal differencing. It looks like there aren't much correlation left when we do the seasonal differencing. Therefore, it could be D=1 and d=0. Let's keep this as one option.

Third set of plots: doing seasonal differencing and ordinary differencing. looks more stationary.

Here: by ACF Plot: q=0,1,2,3; Q=1,2 and PACF plot: p=0,1,2; P=1,2

I'm choosing 0 because when you have more parameters, sometimes, some parameters are insignificant in the presence of other parameters.

e. Model Fitting

```{r}
######################## Check for different combinations ########


#write a funtion
SARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){
  
  #K=(p2+1)*(q2+1)*(P2+1)*(Q2+1)
  
  temp=c()
  d=1
  D=1
  s=12
  
  i=1
  temp= data.frame()
  ls=matrix(rep(NA,9*35),nrow=35)
  
  
  for (p in p1:p2)
  {
    for(q in q1:q2)
    {
      for(P in P1:P2)
      {
        for(Q in Q1:Q2)
        {
          if(p+d+q+P+D+Q<=9)
          {
            
            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))
            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)
            i=i+1
            #print(i)
            
          }
          
        }
      }
    }
    
  }
  
  
  temp= as.data.frame(ls)
  names(temp)= c("p","d","q","P","D","Q","AIC","BIC","AICc")
  
  temp
  
}

```

```{r}
# q=0,1,2,3; Q=1,2 and PACF plot: p=0,1,2; P=1,2, D=1 and d=0,1
output=SARIMA.c(p1=1,p2=3,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=3,data=USgas)
#output

knitr::kable(output)
output[which.min(output$AIC),] 
output[which.min(output$BIC),]
output[which.min(output$AICc),]

```

ARIMA(1,1,1)x(0,1,1)12 is the model suggested above.

```{r,message=FALSE,warning=FALSE}
###### Set Seed for Reproducibility ######
set.seed(123)

###### Fit SARIMA Model and Capture Output ######
model_output <- capture.output(sarima(USgas, 1, 1, 1, 0, 1, 1, 12))

###### Find the Line Numbers Dynamically Based on a Keyword ######
start_line <- grep("Coefficients", model_output)  # Locate where coefficient details start
end_line <- length(model_output)  # Last line of output

###### Print the Relevant Section Automatically ######
cat(model_output[start_line:end_line], sep = "\n")

```
`The Standard Residual Plot` appears good, displaying okay stationarity with a nearly constant mean and variation.

`The Autocorrelation Function (ACF)` plot shows almost no correlation indicating that the model has harnessed everything that left is white noise. This indicates a good model fit.

`The Quantile-Quantile (Q-Q)` Plot still demonstrates near-normality.

`The Ljung-Box test` results reveal values below the 0.05 (5% significance) threshold, indicating there's some significant correlation left.

`$ttable:` all coefficients are significant.

f. Model Fitting

```{r}
fit <- Arima(USgas, order=c(1,1,1), seasonal=c(0,1,1))
summary(fit)
```

g. Forecasting

```{r}

fit %>% forecast(h=36) %>% autoplot() #next 3 years

sarima.for(USgas, 36, 1,1,1,0,1,1,12)


```

h. Compare with Benchmark methods

```{r}
fit <- Arima(USgas, order=c(1,1,1), seasonal=c(0,1,1))

autoplot(USgas) +
  autolayer(meanf(USgas, h=36),
            series="Mean", PI=FALSE) +
  autolayer(naive(USgas, h=36),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(USgas, h=36),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(USgas, h=36, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit,36), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))
```
fit looks a little better than `snaive` because the fit kind of captures the trend.


```{r}
f2 <- snaive(USgas, h=36) 

accuracy(f2)
summary(fit)

```

Model error measurements are much lower than `snaive` benchmark method.

Therefore, our fitted model is good.

## Example 3: Monthly Airline Passenger Numbers 1949-1960

This follows the same procedure as we discussed before.

```{r}

###### Load and Inspect AirPassengers Data ######
x <- AirPassengers
str(x)

###### Plot Original Data ######
autoplot(x) +
  ggtitle("AirPassengers Data") +
  xlab("Year") +
  ylab("Number of Passengers") +
  theme_minimal()

###### Apply Log Transformation and Differencing ######
lx <- log(x)
dlx <- diff(lx)
ddlx <- diff(dlx, lag = 12)

###### Plot Transformed Series ######
plot.ts(cbind(Original = x, Log_Transformed = lx, First_Diff = dlx, Seasonal_Diff = ddlx), 
        main = "AirPassengers Data Transformations")

###### Seasonal Plots ######
par(mfrow = c(2, 1))
monthplot(dlx, main = "Month Plot of First Differenced Log Data")
monthplot(ddlx, main = "Month Plot of Seasonal Differenced Data")

###### ACF and PACF Plots ######
acf2(ddlx, 50)
```



```{r}
log(x) %>% diff() %>% ggtsdisplay()
log(x) %>% diff(12) %>% ggtsdisplay()
log(x) %>% diff() %>%diff(12) %>% ggtsdisplay() #this is better
#q=1,3; Q=1; p=1,3; P=1
```

```{r}
# #q=1,3; Q=1; p=1,3; P=1, D=1 and d=0,1
output=SARIMA.c(p1=1,p2=4,q1=1,q2=4,P1=1,P2=2,Q1=1,Q2=2,data=log(x))
#output

#knitr::kable(output)
output[which.min(output$AIC),] 
output[which.min(output$BIC),]
output[which.min(output$AICc),]

```



```{r}

###### Fit SARIMA Models and Display Diagnostics ######

# ARIMA(1,1,1)x(0,1,1)[12]
model_output11 <- capture.output(sarima(lx, 1, 1, 1, 0, 1, 1, 12))
cat(model_output11[grep("Coefficients", model_output11):length(model_output11)], sep = "\n")

# ARIMA(0,1,1)x(0,1,1)[12] - Best Model
model_output12 <- capture.output(sarima(lx, 0, 1, 1, 0, 1, 1, 12))
cat(model_output12[grep("Coefficients", model_output12):length(model_output12)], sep = "\n")

# ARIMA(1,1,0)x(0,1,1)[12]
model_output13 <- capture.output(sarima(lx, 1, 1, 0, 0, 1, 1, 12))
cat(model_output13[grep("Coefficients", model_output13):length(model_output13)], sep = "\n")
```

#### Forecasting

```{r}
#chosen model : forecasting
sarima.for(lx, 12, 0,1,1, 0,1,1,12)


```

### Benchmark: Seasonal Naive

```{r}

fit=Arima(lx,order=c(0,1,1),seasonal=c(0,1,1))
autoplot(lx) +
  autolayer(meanf(lx, h=12),
            series="Mean", PI=FALSE) +
  autolayer(naive(lx, h=12),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(lx, h=12),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(lx, drift=TRUE, h=12),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit,12), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))
```

```{r}
###### Apply Seasonal Naive Forecast to Log-Transformed AirPassengers Data ######
f2 <- snaive(lx, h = 36)

###### Check Residuals of the Seasonal Naive Model ######
checkresiduals(f2)

###### Evaluate Forecast Accuracy ######
accuracy(f2)

###### Display Model Summary ######
summary(f2)
```



## Example 4 : Corticosteroid drug sales in Australia

 We will try to forecast monthly corticosteroid drug sales in Australia. These are known as H02 drugs under the Anatomical Therapeutic Chemical classification scheme.

```{r}
###### Plot Original H02 Sales Data ######
autoplot(h02) +
  ggtitle("H02 Sales Data") +
  xlab("Year") +
  ylab("Sales (Million Scripts)") +
  theme_minimal()

###### Log-Transform H02 Sales Data ######
lh02 <- log(h02)

###### Plot Original and Log-Transformed H02 Sales Data ######
cbind("H02 Sales (Million Scripts)" = h02,
      "Log H02 Sales" = lh02) %>%
  autoplot(facets = TRUE) +
  ggtitle("Original and Log-Transformed H02 Sales") +
  xlab("Year") +
  ylab("") +
  theme_minimal()
```

Data from July 1991 to June 2008 are plotted. There is a small increase in the variance with the level, so we take logarithms to stabilise the variance.

The data are strongly seasonal and obviously non-stationary, so seasonal differencing will be used. The seasonally differenced data are shown below. It is not clear at this point whether we should do another difference or not. 

The last few observations appear to be different (more variable) from the earlier data. This may be due to the fact that data are sometimes revised when earlier sales are reported late.

```{r}
###### Plot ACF of Log-Transformed H02 Sales Data ######
ggAcf(lh02) +
  ggtitle("ACF of Log-Transformed H02 Sales")
  
```
We can see high correlation and seasonal correlation. Therefore, let's try seasonal differencing.

```{r} 
###### Apply Seasonal Differencing (D=1) to Log-Transformed H02 Sales Data ######

# Seasonal differencing using pipe
lh02 %>% 
  diff(lag = 12) %>% 
  ggtsdisplay(xlab = "Year", 
              main = "Seasonally Differenced H02 Scripts")

# Alternative approach using explicit variable
sdf <- diff(lh02, lag = 12)

###### Plot ACF and PACF for Seasonally Differenced Data ######
ggAcf(sdf) +
  ggtitle("ACF of Seasonally Differenced H02 Sales") 

ggPacf(sdf) +
  ggtitle("PACF of Seasonally Differenced H02 Sales") 

```
From the above ACF plot, You can see that seasonal correlation is removed but there is ordinary correlation left.

Let's do an ordinary differencing on top of seasonal differencing.

```{r}
lh02 %>% diff(lag=12) %>%diff() %>%
  ggtsdisplay(xlab="Year",
    main="Seasonally & Ordinary differenced H02 scripts")
```


In the plots of the differenced data, there are spikes in the PACF at lags 12 and almost at 24, and  seasonal lag 12 in the ACF.  The pattern in the ACF is not indicative of any simple model.

So q=0,1 ; p=1,2; Q=0,1,2; P=0,1; d=1; D=1; s=12

We fit these model, and compare the AIC,BIC and AICc values.

```{r}

#write a funtion
SARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){
  
#K=(p2+1)*(q2+1)*(P2+1)*(Q2+1)
  
  temp=c()
  d=1
  D=1
  s=12
  
  i=1
  temp= data.frame()
  ls=matrix(rep(NA,9*24),nrow=24)
  
  
  for (p in p1:p2)
  {
    for(q in q1:q2)
    {
      for(P in P1:P2)
      {
        for(Q in Q1:Q2)
        {
          if(p+d+q+P+D+Q<=10)
          {
            
            model<- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))
            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)
            i=i+1
            #print(i)
            
          }
          
        }
      }
    }
    
  }
  
  
  temp= as.data.frame(ls)
  names(temp)= c("p","d","q","P","D","Q","AIC","BIC","AICc")
  
  temp
  
}

output=SARIMA.c(p1=1,p2=2,q1=0,q2=1,P1=0,P2=1,Q1=0,Q2=2,data=lh02)
#SARIMA.c(2,3,1,2,1,2,1,3,data=lh02)

minaic=output[which.min(output$AIC),]
minbic=output[which.min(output$BIC),]

minaic
minbic

```

The models suggested are: ARIMA(2,1,1)x(0,1,2)
ARIMA(2,1,0)x(0,1,1)

Another way of doing this:

```{r}
d=1
D=1
s=12

ARIMA_fit <- list()

## set counter
cc <- 1

for (p in 2:3)#2 p=1,2
{
  for(q in 1:2)#2 q=1,2
  {
    for(P in 1:2)#2 P=0,1
    {
      for(Q in 1:3)#3 Q=0,1,2
      {
        if(p-1+d+q-1+P-1+D+Q-1<=10)
        {
          
          ARIMA_fit[[cc]] <- Arima(lh02,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))
          cc <- cc + 1             
        }
        
      }
    }
  }

}


# get AIC values for model evaluation
ARIMA_AIC <- sapply( ARIMA_fit, function(x) AIC(x)) 
## model with lowest AIC is the best
ARIMA_fit[[which(ARIMA_AIC == min(ARIMA_AIC))]]

ARIMA_BIC <- sapply(ARIMA_fit , function(x) BIC(x)) 

## model with lowest BIC is the best 
ARIMA_fit[[which(ARIMA_BIC == min(ARIMA_BIC))]]


#ARIMA_fit[[which(ARIMA_AIC == min(ARIMA_AIC)) & which(ARIMA_BIC == min(ARIMA_BIC)) ]]

```


The models suggested are: ARIMA(2,1,1)x(0,1,2)
ARIMA(2,1,0)x(0,1,1)

```{r}
(fit <- Arima(h02, order=c(2,1,1), seasonal=c(0,1,2),lambda=0))
checkresiduals(fit, lag=36)


#or

(fit2 <- Arima(lh02, order=c(2,1,0), seasonal=c(0,1,1)))
checkresiduals(fit2, lag=36)
```


In another article <https://otexts.com/fpp2/seasonal-arima.html> they have found that the best  model is ARIMA(3,0,1)(0,1,2)12.
 

```{r}
(fit <- Arima(h02, order=c(3,0,1), seasonal=c(0,1,2),lambda=0))
checkresiduals(fit, lag=36)

```

Model Diagnostic: There are a few significant spikes in the ACF, and the model fails the Ljung-Box test. The model can still be used for forecasting, but the prediction intervals may not be accurate due to the correlated residuals.

```{r}
###### Capture SARIMA Model Outputs ######

# SARIMA(2,1,1)(0,1,2)[12]
model_output1 <- capture.output(sarima(lh02, 2, 1, 1, 0, 1, 2, 12))
cat(model_output1[grep("Coefficients", model_output1):length(model_output1)], sep = "\n")

# SARIMA(2,1,0)(0,1,1)[12]
model_output2 <- capture.output(sarima(lh02, 2, 1, 0, 0, 1, 1, 12))
cat(model_output2[grep("Coefficients", model_output2):length(model_output2)], sep = "\n")

# SARIMA(3,0,1)(0,1,2)[12]
model_output3 <- capture.output(sarima(lh02, 3, 0, 1, 0, 1, 2, 12))
cat(model_output3[grep("Coefficients", model_output3):length(model_output3)], sep = "\n")
```

`The Standard Residual Plot` appears good in all 3 models, displaying okay stationarity with a nearly constant mean and variation.

`The Autocorrelation Function (ACF)` plot shows nearly no correlation in all 3 models.

`The Quantile-Quantile (Q-Q)` Plots still demonstrates near-normality.

`The Ljung-Box test` results reveal values above the 0.05 (5% significance) threshold, indicating the absence of significant correlation and suggesting a well-fitted model.

`$ttable:` 

`sarima(lh02,2,1,1,0,1,2,12)` all coefficients are significant except ma1. ;aic = -484.51
`sarima(lh02,2,1,0,0,1,1,12)` all coefficients are significant. ;aic = -482.78
`sarima(lh02,3,0,1,0,1,2,12)` all coefficients are significant. ;aic = -489.99



Next we will try using the automatic ARIMA algorithm.

```{r}
auto.arima(lh02)
```

Running auto.arima() with all arguments left at their default values led to an ARIMA(2,1,1)(0,1,2) 12
model. However, as you can see from the below results from the `checkresiduals()`; model still fails the Ljung-Box test for 36 lags. Sometimes it is just not possible to find a model that passes all of the tests.

```{r}
(fit4 <- Arima(lh02, order=c(2,1,1), seasonal=c(0,1,2)))
checkresiduals(fit4, lag=36)

```

It looks however, `sarima(lh02,3,0,1,0,1,2,12)` is a better model.

```{r}

fit<-h02 %>%
  Arima(order=c(3,0,1), seasonal=c(0,1,2), lambda=0)

autoplot(h02) +
  autolayer(meanf(h02, h=36),
            series="Mean", PI=FALSE) +
  autolayer(naive(h02, h=36),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(h02, h=36),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(h02, h=36, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit,36), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))
```

```{r}
f2 <- snaive(h02, h=36) 

#checkresiduals(f2)

accuracy(f2)
summary(fit)
```
Accuracy measurements are smaller in the fitted model indicating a better model.

  
  
Forecasts from the ARIMA(3,0,1)(0,1,2)12 model.

```{r}
h02 %>%
  Arima(order=c(3,0,1), seasonal=c(0,1,2), lambda=0) %>%
  forecast() %>%
  autoplot() +
    ylab("H02 sales (million scripts)") + xlab("Year")
```






